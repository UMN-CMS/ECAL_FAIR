{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dying-conversation",
   "metadata": {},
   "source": [
    "This is the notebook to run the seq2seq network. It starts with a preprocessed file with p2_calib being the value to predict, and int_deliv_inv_ub and calib_time being the best values to use. It's important to note that at this point, some of the lumi measurements are taken a bit far from the calibration times. this can be seen by the difference between the lumi-section time and the calib_time values. The best data probably just consistents of the points where these are close.\n",
    "\n",
    "All data is in its original units.\n",
    "\n",
    "Also, I'm running this in the Python 3.7.1 Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hazardous-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the stuff\n",
    "import pandas as pd #dataframes etc\n",
    "import matplotlib.pyplot as plt #plotting\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from common.utils import TimeSeriesTensor, create_evaluation_df, mape, scale_shrinker\n",
    "#now we bring in the keras tensorflow model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
    "\n",
    "from math import pow, floor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "automotive-butter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p2</th>\n",
       "      <th>int_deliv_inv_ub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-05-12 09:01:31</th>\n",
       "      <td>0.000267</td>\n",
       "      <td>1.912590e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-12 10:01:31</th>\n",
       "      <td>0.000199</td>\n",
       "      <td>1.786448e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-12 11:01:31</th>\n",
       "      <td>0.000203</td>\n",
       "      <td>1.664305e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-12 12:01:31</th>\n",
       "      <td>0.000395</td>\n",
       "      <td>3.387666e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-12 13:01:31</th>\n",
       "      <td>0.000471</td>\n",
       "      <td>3.200991e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           p2  int_deliv_inv_ub\n",
       "2018-05-12 09:01:31  0.000267      1.912590e+07\n",
       "2018-05-12 10:01:31  0.000199      1.786448e+07\n",
       "2018-05-12 11:01:31  0.000203      1.664305e+07\n",
       "2018-05-12 12:01:31  0.000395      3.387666e+07\n",
       "2018-05-12 13:01:31  0.000471      3.200991e+07"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data\n",
    "test = pd.read_csv('../data/test_diff.csv', index_col=0)\n",
    "valid = pd.read_csv('../data/valid_diff.csv', index_col=0)\n",
    "train = pd.read_csv('../data/train_diff.csv', index_col=0)\n",
    "#set index to datetime periods\n",
    "#test.index = pd.to_datetime(test.index).to_period('H')\n",
    "#valid.index = pd.to_datetime(valid.index).to_period('H')\n",
    "#train.index = pd.to_datetime(train.index).to_period('H')\n",
    "#set index to datetime\n",
    "test.index = pd.to_datetime(test.index)\n",
    "valid.index = pd.to_datetime(valid.index)\n",
    "\n",
    "train = train.append(valid)\n",
    "train.index = pd.to_datetime(train.index)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "spare-surgeon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p2</th>\n",
       "      <th>int_deliv_inv_ub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.734000e+03</td>\n",
       "      <td>3.734000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.942061e-17</td>\n",
       "      <td>-4.524441e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000134e+00</td>\n",
       "      <td>1.000134e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.202259e+00</td>\n",
       "      <td>-8.722823e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.913427e-01</td>\n",
       "      <td>-8.722823e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.828191e-01</td>\n",
       "      <td>-4.994302e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.939159e-01</td>\n",
       "      <td>8.539115e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.162806e+00</td>\n",
       "      <td>2.434024e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 p2  int_deliv_inv_ub\n",
       "count  3.734000e+03      3.734000e+03\n",
       "mean  -2.942061e-17     -4.524441e-16\n",
       "std    1.000134e+00      1.000134e+00\n",
       "min   -4.202259e+00     -8.722823e-01\n",
       "25%   -1.913427e-01     -8.722823e-01\n",
       "50%    1.828191e-01     -4.994302e-01\n",
       "75%    5.939159e-01      8.539115e-01\n",
       "max    3.162806e+00      2.434024e+00"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we will scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = StandardScaler()\n",
    "y_scaler = StandardScaler() #we'll use the y-scaler later\n",
    "y_scaler.fit(train[['p2']])\n",
    "train[['p2', 'int_deliv_inv_ub']] = scaler.fit_transform(train)\n",
    "train.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "opposed-andrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p2</th>\n",
       "      <th>int_deliv_inv_ub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1166.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.030238</td>\n",
       "      <td>-0.604280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.607155</td>\n",
       "      <td>0.677192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.891640</td>\n",
       "      <td>-0.872282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.089422</td>\n",
       "      <td>-0.872282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.060977</td>\n",
       "      <td>-0.872282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.257269</td>\n",
       "      <td>-0.872281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.381403</td>\n",
       "      <td>2.171513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                p2  int_deliv_inv_ub\n",
       "count  1166.000000       1166.000000\n",
       "mean      0.030238         -0.604280\n",
       "std       0.607155          0.677192\n",
       "min      -3.891640         -0.872282\n",
       "25%      -0.089422         -0.872282\n",
       "50%       0.060977         -0.872282\n",
       "75%       0.257269         -0.872281\n",
       "max       2.381403          2.171513"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[['p2', 'int_deliv_inv_ub']] = scaler.transform(test)\n",
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the data\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "willing-trading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.59420064  0.25958877]\n",
      " [ 0.44594011  0.18332401]\n",
      " [ 0.45604353  0.10947734]\n",
      " [ 0.87168012  1.15141108]\n",
      " [ 1.03762608  1.0385484 ]\n",
      " [ 0.68422353  0.92382076]\n",
      " [ 0.38075093  0.62462487]\n",
      " [ 0.89124915  0.35741122]\n",
      " [ 0.32194582  0.3213169 ]\n",
      " [-1.18816483  0.66245371]]\n",
      "[-1.67139609]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2645, 10, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "\n",
    "#Define an input sequence and process it.\n",
    "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "# Save model\n",
    "model.save(\"s2s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
